Seçilen datanın üstünde gerekli işlemler yaptık. Eksik verileri doldurma, sütun düzenleme , kategorik verileri nümeriğe çevirme işlemleri ,VIF yöntemi kullanarak veriler arası ilişkileri bulma,  F1 ve doğruluk hesaplamaları gibi . Eksik verileri veri imputasyonu yardımıyla doldurduk. İmputasyon tekniklerinden olan SimpleImputer ile nümerikleri ortalama, kategorikleri en çok tekrarlayan metoduyla doldurduk ve verisetini bozmadan düzenledik. Kategorik verileri makinenin algılaması için nümerik tipine çevirdik ve bunu  LabelEncoder kullanarak çevirdik. OneHotEncoder kullanarak tek sütunda anlaşılmayan verileri sütunlara ayırdık. Artık okunması daha kolay verilere sahip olduk. Sahip olduğumuz sütunlara anlaşılması kolay olsun diye isim verdik.OHE kullanılarak ayırılan sütunlardan bazıları dummy variable olduğu için verisetinden çıkardık. VIF yöntemi yardımıyla bazı verileri datasetten çıkardık(Verisetindeki VIF değeri 2 den fazla olan parametreleri).heatmap yardımıyla Correlasyon matrix grafiğini elde ettik hangi parametrelerin etki ettiklerini gördük.SMOTE uygulaması yardımıyla parametrelerin azlığı veya çokluğu sorunun çözüp dengeli bir train test işlemine tabi tuttuk. StandartScale kullanalarak veri değeri fazla olan parametreleri küçültme işlemi yaptık çünkü modeli fazla etkilemesini istemiyoruz.KNN SVC XGBOOST GRADIENTBOOST LOGİSTİC REGRESSİON, DECISION TREE , RANDOM FOREST metodlarını modelimiz için uygun olup olmadıklarını confusion matrixine bakarak ölçtük.  En doğru modeli veren KNN ve logistic regresyon olduğu kanısına vardık ancak gerekli veri üzerinde manipülasyonlar yapılarak bu modellerin değişmesi olası seviyededir. Her bir modelin kendine ait avantaj dezavantajı olduğu için en doğru modeli seçmek biraz zorlayıcı olacaktır. En sonda doğruluk oranlarını öğrendik . En iyi sonucu verene kadar data üstünde gerekli işlemleri yapacağız.




############333

Bundan sonraki uygulamalarda veriyi bütün sorunlarından arınmış şekile getirmeye çalışacağız. Modellerin düşük doğruluk oranı vermesinin sebeplerinden olduğunu düşünüyoruz. İkinci bir neden ise bağımlı değişkeni ikili(binary) hale getirmek doğruluk oranlarını %85 civarına getirmiştir ancak bu durum tam istediğimiz bir şey olmadığı için en son ihtimal bu yöntemi deneyeceğiz. Kodun devamında derin öğrenme metodlarını veriseti üzerindeki etkisini ölçmek ve daha iyi sonuçlar elde edebilmek için kullanmayı düşünüyoruz. Koda matplotlib yardımıyla insanların anlayabilmesi için okunabilirliği fazla olan grafikler ekleyeceğiz. verisetini anlamanın modeli eğitmek için çok önemli olduğunu biliyoruz. Zaten correlasyon matrixi ile verinin okunabilirliğini anladık. 



Logistic regression
[[93 27  6 10  8]
 [23 32 22  7  9]
 [ 4  2 12  8 11]
 [ 4  1 12  5 11]
 [ 3  0  4  2  6]]

KNN
[[89 25 10 13  7]
 [21 36 20 13  3]
 [ 1  4 14  8 10]
 [ 2  4 14  5  8]
 [ 2  1  4  5  3]]

svc
[[87 31  7 13  6]
 [19 34 16 19  5]
 [ 2  2 11 12 10]
 [ 3  3  8 11  8]
 [ 2  0  4  5  4]]

Rassal Ağaçlar
[[94 33  9  7  1]
 [31 38 13 10  1]
 [ 7  5 11  7  7]
 [ 5  8 12  5  3]
 [ 3  1  4  4  3]]

--- XGBoost Karışıklık Matrisi ---
[[93 27 12 10  2]
 [28 36 13 12  4]
 [ 4  9 11  8  5]
 [ 5  6 12  8  2]
 [ 4  2  3  4  2]]
###########
Yapılan araştırmalar sonucunda makine öğrenmesi metodları hakkında bilgi sahibi olundu ve test işlemlerine başlanıldı. Veri düzenlendikten sonra en kötü sonucu veren Naive Bayes, modelin tüm özelliklerin birbirinden tamamen bağımsız olması nedeniyle yapılan testler sonucu dibi görmüştür. Parametrelerin birbiri ile bağlantısı olmaması doğruluk oranını düşürmüştür. Decision tree metoduda beklentinin altında kalmıştır. Modeli iyi analiz etmesine rağmen kötü sonuç vermesi tek başına kullanıldığında metodun yetersizliği gözümüze çarpmıştır. Random Forest KNN SVC logistic regresyon ve XGboostun doğruluk oranları birbirlerine çok yakındır. Bu yakınlık hepsinin aynı seviyede doğru bildiğini düşündürebilir ancak burada göze çarpan bazı durumlar söz konusudur. Veriden dolayı bilinmesi zor olan evre 4 sınıfını en iyi tahmin eden logistic regresyon olurken evre 3 sınıfında kötü bir performans göstermiştir. Hepsi evre 0 sınıfını hepsi çok rahat tahmin ederken evre 3 sınıfını en iyi tahmini SVC bulmuştur. Sonuçları en iyi çıkartan metod Gradient boosting olmuştur. SMOTE uygulamasından sonra tahmin oranları yükselmiştir. SMOTE yüzünden oranı düşen KNN en yüksek ikinci tahmin eden metod olmuştur. Bütün metodların bu kadar düşük olmasının sebebi outlier verileri verisetinden çıkarmamamız denebilir. 







############ Manipüle etme

Karar kılınan verisetinde öncelikle bütün sütunlar ayrılmıştır ve sütunlarda bulunan eksik veriler tespit edilmiştir. Eksik veri bulunan sütunlar eğer nümerik ise SimpleImputer yardımıyla ortalaması alınıp boşluklara(Nan) eklenmiştir. Kategorik verilerde ise en çok kullanılan hangi değer ise ona göre doldurulmuştur. Makinenin daha iyi karar verebilmesi için kategorik verileri Label encoder kullanarak sayısal değere çevrilmiştir. Çevrilen veriler OHE kullanılarak sütunlara ayrılmıştır ve sütunlara isimleri değiştirilmiştir. Artık daha fazla sütun vardır ancak anlaşılması daha kolaylaşmıştır. Önceden ayrılan verisetini şimdi bağımlı değişken(heart_disease) hariç tekrardan birleştirilmiştir. Bağımlı değişkeni ayırmamızın sebebi train test splite sokarken makinenin hangi veriyi tahmin etmesi gerektiğini anlayabilmesi içindir. Veri içinde OHE yardımıyla sütunlara ayrılan parametrelerin bazıları silinmiştir. Dummy variables sorunu yüzünden verinin bozulmasını önledik. VIF 
yöntemini kullanarak birbiri ile çok fazla etkileşim bulunduran parametreleri kaldırdık. VIF değeri fazla olan parametreler veri tahminini zorlaştırıyordu. Testlere geçmeden önce train test diye ayrılan değişkenleri scale işlemini uyguladık çünkü parametreler arası üstünlük olmasını istemiyoruz. 
En son olarakda Outlier değerleri datadan çıkarmamız gerektiğini anladık. Doğruluk oranlarını düşürdüğü için iyi bir tahmin yapamıyordu metodlar. Son işlemide uyguladığımız zaman data manipüle işlemi sona erecektir.











